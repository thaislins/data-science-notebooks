{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Introduction.ipynb","version":"0.3.2","provenance":[]}},"cells":[{"metadata":{"id":"HwlWT3cPzERt","colab_type":"text"},"cell_type":"markdown","source":["Identification:\n","\n","```python\n","name = [\"Pythonildo Conda\", \"Javanildo Beans\"]\n","id   = [20181234, 20049082]\n","```\n"]},{"metadata":{"id":"QM0kP8zABtVA","colab_type":"text"},"cell_type":"markdown","source":["\n","<img width=\"60\" src=\"https://drive.google.com/uc?export=view&id=1JQRWCUpJNAvselJbC_K5xa5mcKl1gBQe\"> \n","\n"]},{"metadata":{"id":"HAT6cOVf5N-h","colab_type":"code","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":87},"outputId":"72eddaa6-856c-4809-9ae5-f6c0f65dec0b","executionInfo":{"status":"ok","timestamp":1537301073241,"user_tz":180,"elapsed":118889,"user":{"displayName":"Ivanovitch Silva","photoUrl":"//lh4.googleusercontent.com/-baHwkIBEacY/AAAAAAAAAAI/AAAAAAAAFo0/aWRaXNQgy7Q/s50-c-k-no/photo.jpg","userId":"116628038672433119071"}}},"cell_type":"code","source":["# Uploading files from your local file system\n","\n","from google.colab import files\n","uploaded = files.upload()\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-e845eac7-dbbb-442e-93af-d6090d56b298\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-e845eac7-dbbb-442e-93af-d6090d56b298\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving autos.csv to autos.csv\n","User uploaded file \"autos.csv\" with length 9617699 bytes\n"],"name":"stdout"}]},{"metadata":{"id":"yDhBZZ6PvG69","colab_type":"text"},"cell_type":"markdown","source":["# 1.0 Introduction"]},{"metadata":{"id":"lTKspsacvMZU","colab_type":"text"},"cell_type":"markdown","source":["In this lesson, we'll work with a dataset of used cars from *eBay Kleinanzeigen*, a [classifieds](https://en.wikipedia.org/wiki/Classified_advertising) section of the German eBay website.\n","\n","The dataset was originally [scraped](https://en.wikipedia.org/wiki/Web_scraping) and uploaded to [Kaggle](https://www.kaggle.com/orgesleka/used-cars-database/data). We've made a few modifications from the original dataset that was uploaded to Kaggle:\n","\n","- We sampled 50,000 data points from the full dataset, to ensure your code runs quickly\n","- We dirtied the dataset a bit to more closely resemble what you would expect from a scraped dataset (the version uploaded to Kaggle was cleaned to be easier to work with)\n","\n","The data dictionary provided with data is as follows:\n","\n","\n","- **dateCrawled** - When this ad was first crawled. All field-values are taken from this date.\n","- **name** - Name of the car.\n","- **seller** - Whether the seller is private or a dealer\n","- **offerType** - The type of listing\n","- **price** - The price on the ad to sell the car.\n","- **abtest** - Whether the listing is included in an A/B test.\n","- **vehicleType** - The vehicle Type.\n","- **yearOfRegistration** - The year in which which year the car was first registered.\n","- **gearbox** - The transmission type.\n","- **powerPS** - The power of the car in PS.\n","- **model** - The car model name.\n","- **kilometer** - How many kilometers the car has driven.\n","- **monthOfRegistration** - The month in which which year the car was first registered.\n","- **fuelType** - What type of fuel the car uses.\n","- **brand** - The brand of the car.\n","- **notRepairedDamage** - If the car has a damage which is not yet repaired.\n","- **dateCreated** - The date on which the eBay listing was created.\n","- **nrOfPictures** - The number of pictures in the ad.\n","- **postalCode** - The postal code for the location of the vehicle.\n","- **lastSeenOnline** - When the crawler saw this ad last online.\n","\n","The aim of this project is to clean the data and analyze the included used car listings. You'll also become familiar with some of the unique benefits jupyter notebook provides for pandas.\n","\n","Let's start by importing the libraries we need and reading the dataset into pandas.\n","\n","**Exercise**\n","\n","<img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\">\n","\n","\n","- Start by writing a paragraph in a markdown cell introducing the project and the dataset.\n","- Import the pandas and NumPy libraries\n","- Read the **autos.csv** CSV file into pandas, and assign it to the variable name **autos**.\n","    - Try without specifying any encoding (which will default to **UTF-8**)\n","    - If you get an encoding error, try the next two most popular encodings (**Latin-1** and **Windows-1252**) until you are able to read the file without error.\n","- Create a new cell with just the variable **autos** and run this cell.\n","A neat feature of jupyter notebook is its ability to render the first few and last few values of any pandas object.\n","- Use the **DataFrame.info()** and **DataFrame.head()** methods to print information about the **autos** dataframe, as well as the first few rows.\n","- Write a markdown cell briefly describing your observations.\n","\n"]},{"metadata":{"id":"zHDkOQhzvkvT","colab_type":"code","colab":{}},"cell_type":"code","source":["# put your code here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0K84WqLpVGxa","colab_type":"text"},"cell_type":"markdown","source":["# 2.0 Cleaning Column Names\n","\n"]},{"metadata":{"id":"P7FvLuVXVe6e","colab_type":"text"},"cell_type":"markdown","source":["From the work we did in the last section, we can make the following observations:\n","\n","- The dataset contains 20 columns, most of which are strings.\n","- Some columns have **null** values, but none have more than ~20% **null** values.\n","- The column names use [camelcase](https://en.wikipedia.org/wiki/Camel_case) instead of Python's preferred [snakecase](https://en.wikipedia.org/wiki/Snake_case), which means we can't just replace spaces with underscores.\n","\n","Let's convert the column names from **camelcase** to **snakecase** and reword some of the column names based on the data dictionary to be more descriptive.\n","\n","**Exercise**\n","\n","<img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\">\n","\n","- Use the **DataFrame.columns** attribute to print an array of the existing column names.\n","- Copy that array and make the following edits to columns names:\n","    - **yearOfRegistration** to **registration_year**\n","    - **monthOfRegistration** to **registration_month**\n","    - **notRepairedDamage** to **unrepaired_damage**\n","    - **dateCreated** to **ad_created**\n","    - The rest of the columnn names from camelcase to snakecase.\n","- Assign the modified column names back to the **DataFrame.columns** attribute.\n","- Use **DataFrame.head()** to look at the current state of the autos dataframe.\n","- Write a markdown cell explaining the changes you made and why."]},{"metadata":{"id":"saqI9ZDMrOOV","colab_type":"code","colab":{}},"cell_type":"code","source":["# put your code here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0xinTh-JV6ka","colab_type":"text"},"cell_type":"markdown","source":["# 3.0 Initial Exploration and Cleaning"]},{"metadata":{"id":"pF8jCLKYqJ7N","colab_type":"text"},"cell_type":"markdown","source":["Now let's do some basic data exploration to determine what other cleaning tasks need to be done. Initially we will look for:\n","\n","- Text columns where all or almost all values are the same. These can often be dropped as they don't have useful information for analysis.\n","- Examples of numeric data stored as text which can be cleaned and converted.\n","\n","The following methods are helpful for exploring the data:\n","- **DataFrame.describe()** (with **include='all'** to get both categorical and numeric columns) \n","- **Series.value_counts()** and **Series.head()** if any columns need a closer look.\n","\n","**Exercise**\n","\n","<img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\">\n","\n","- Use **DataFrame.describe()** to look at descriptive statistics for all columns.\n","- Write a markdown cell noting:\n","  - Any columns that have mostly one value that are candidates to be dropped\n","  - Any columns that need more investigation.\n","  - Any examples of numeric data stored as text that needs to be cleaned.\n","- If you need to investigate any columns more, do so and write up any additional things you found.\n","- You likely found that the **price** and **odometer** columns are numeric values stored as text. For each column:\n","    - Remove any non-numeric characters.\n","    - Convert the column to a numeric dtype.\n","    - Use **DataFrame.rename()** to rename the column to **odometer_km**."]},{"metadata":{"id":"q2uBgqtrqkWC","colab_type":"code","colab":{}},"cell_type":"code","source":["# put your code here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QD7z0bp2rSbB","colab_type":"text"},"cell_type":"markdown","source":["# 4.0 Exploring the Odometer and Price Columns"]},{"metadata":{"id":"LeBXgFoUrbKg","colab_type":"text"},"cell_type":"markdown","source":["From the last section, we learned that there are a number of text columns where almost all of the values are the same (**seller** and **offer_type**). We also converted the **price** and **odometer** columns to numeric types and renamed **odometer** to **odometer_km**.\n","\n","Let's continue exploring the data, specifically looking for data that doesn't look right. We'll start by analyzing the **odometer_km** and **price** columns. Here's the steps we'll take:\n","\n","- Analyze the columns using minimum and maximum values and look for any values that look unrealistically high or low (outliers) that we might want to remove.\n","- We'll use:\n","  - **Series.unique().shape** to see how many unique values\n","  - **Series.describe()** to view min/max/median/mean etc\n","  - **Series.value_counts()**, with some variations:\n","    - chained to **.head()** if there are lots of values.\n","    - Because **Series.value_counts()** returns a series, we can use **Series.sort_index()** with **ascending=True** or **False** to view the highest and lowest values with their counts (can also chain to head() here).\n","    - When removing outliers, we can do df[(df[\"col\"] > x ) & (df[\"col\"] < y )], but it's more readable to use df[df[\"col\"].[between(x,y)](https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.Series.between.html)]\n","    \n","\n","**Exercise**\n","\n","<img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\">\n","\n","\n","- For each of the **odometer_km** and **price** columns:\n","  - Use the techniques above to explore the data\n","  - If you find there are outliers, remove them and write a markdown paragraph explaining your decision.\n","  - After you have removed the outliers, make some observations about the remaining values, with examples of how we can use that to extract **YYYY**, **YYYY-MM** or **YYYY-MM-DD** from those columns."]},{"metadata":{"id":"XUAfmmKcsT6w","colab_type":"code","colab":{}},"cell_type":"code","source":["# put your code here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KbZcTdc3tSGu","colab_type":"text"},"cell_type":"markdown","source":["# 5.0 Exploring the date columns\n","\n"]},{"metadata":{"id":"rC3rAMuptawF","colab_type":"text"},"cell_type":"markdown","source":["Let's now move on to the date columns and understand the date range the data covers.\n","\n","There are 5 columns that should represent date values. Some of these columns were created by the crawler, some came from the website itself. We can differentiate by referring to the data dictionary:\n","\n","\n","- **date_crawled**: added by the crawler\n","- **last_seen**: added by the crawler\n","- **ad_created**: from the website\n","- **registration_month**: from the website\n","- **registration_year**: from the website\n","\n","Right now, the **date_crawled**, **last_seen**, and **ad_created** columns are all identified as string values by pandas. Because these three columns are represented as strings, we need to convert the data into a numerical representation so we can understand it quantitatively. The other two columns are represented as numeric values, so we can use methods like **Series.describe()** to understand the distribution without any extra data processing.\n","\n","Let's first understand how the values in the three string columns are formatted. These columns all represent full timestamp values, like so:\n","\n","```python\n","autos[['date_crawled','ad_created','last_seen']][0:5]\n","```\n","\n","|  |date_crawled | ad_created          | last_seen           |                     |\n","|--------------|---------------------|---------------------|---------------------|\n","| 0            | 2016-03-26 17:47:46 | 2016-03-26 00:00:00 | 2016-04-06 06:45:54 |\n","| 1            | 2016-04-04 13:38:56 | 2016-04-04 00:00:00 | 2016-04-06 14:45:08 |\n","| 2            | 2016-03-26 18:57:24 | 2016-03-26 00:00:00 | 2016-04-06 20:15:37 |\n","| 3            | 2016-03-12 16:58:10 | 2016-03-12 00:00:00 | 2016-03-15 03:16:28 |\n","| 4            | 2016-04-01 14:38:50 | 2016-04-01 00:00:00 | 2016-04-01 14:38:50 |\n","\n","\n","You'll notice that the first 10 characters represent the day (e.g. **2016-03-12**). To understand the date range, we can extract just the date values, use **Series.value_counts()** to generate a distribution, and then sort by the index.\n","\n","To select the first 10 characters in each column, we can use **Series.str[:10]**:\n","\n","```python\n","autos['date_crawled'].str[:10]\n","\n",">>>\n","0        2016-03-26\n","1        2016-04-04\n","2        2016-03-26\n","3        2016-03-12\n","...\n","```\n","\n","**Exercise**\n","\n","<img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\">\n","\n","\n","- Use the workflow we just described to calculate the distribution of values in the **date_crawled**, **ad_created**, and **last_seen** columns (all string columns) as percentages.\n","  - To include missing values in the distribution and to use percentages instead of counts, chain the **Series.value_counts(normalize=True, dropna=False)** method.\n","  - To rank by date in ascending order (earliest to latest), chain the **Series.sort_index()** method.\n","  - Write a markdown cell after each column exploration to explain your observations.\n","- Use **Series.describe()** to understand the distribution of **registration_year**.\n","    - Write a markdown cell explaining your observations."]},{"metadata":{"id":"UynpvHxBt704","colab_type":"code","colab":{}},"cell_type":"code","source":["# put your code here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"o0Kh-87cvYzG","colab_type":"text"},"cell_type":"markdown","source":["# 6.0 Dealing with Incorrect Registration Year Data\n"]},{"metadata":{"id":"A0HZRH3wvaUV","colab_type":"text"},"cell_type":"markdown","source":["One thing that stands out from the exploration we did in the last section is that the **registration_year** column contains some odd values:\n","\n","- The minimum value is 1000, before cars were invented\n","- The maximum value is 9999, many years into the future\n","\n","Because a car can't be first registered before the listing was seen, any vehicle with a registration year above 2016 is definitely inaccurate. Determining the earliest valid year is more difficult. Realistically, it could be somewhere in the first few decades of the 1900s.\n","\n","Let's count the number of listings with cars that fall outside the 1900 - 2016 interval and see if it's safe to remove those rows entirely, or if we need more custom logic.\n","\n","\n","**Exercise**\n","\n","<img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\">\n","\n","\n","- Decide which the highest and lowest acceptable values are for the **registration_year** column.\n","  - Write a markdown cell explaining your decision and why.\n","- Remove the values outside those upper and lower bounds and calculate the distribution of the remaining values using **Series.value_counts(normalize=True)**.\n","  - Write a markdown cell explaining your observations.\n"]},{"metadata":{"id":"C9cCwSrjv8be","colab_type":"code","colab":{}},"cell_type":"code","source":["# put your code here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"f-s-lroVwbr9","colab_type":"text"},"cell_type":"markdown","source":["# 7.0 Exploring Price by Brand\n"]},{"metadata":{"id":"1IKJOb4IwfUW","colab_type":"text"},"cell_type":"markdown","source":["One of the analysis techniques we learned in this course is aggregation. When working with data on cars, it's natural to explore variations across different car brands. We can use aggregation to understand the **brand** column.\n","\n","If you recall in an earlier lesson, we explored how to use loops to perform aggregation. Here's what the process looks like:\n","\n","\n","- Identify the unique values we want to aggregate by\n","- Create an empty dictionary to store our aggregate data\n","- Loop over the unique values, and for each:\n","    - Subset the dataframe by the unique values\n","    - Calculate the mean of whichever column we're interested in\n","    - Assign the val/mean to the dict as k/v.\n","    \n","    \n","**Exercise**\n","\n","<img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\">\n","\n","\n","- Explore the unique values in the **brand** column, and decide on which brands you want to aggregate by.\n","  - You might want to select the top 20, or you might want to select those that have over a certain percentage of the total values (e.g. > 5%).\n","  - Remember that **Series.value_counts()** produces a series with index labels, so you can use **Series.index** attribute to access the labels, should you wish.\n","- Write a short paragraph describing the brand data, and explaining which brands you've chosen to aggregate on.\n","- Create an empty dictionary to hold your aggregate data.\n","  - Loop over your selected brands, and assign the mean price to the dictionary, with the brand name as the key.\n","  - Print your dictionary of aggregate data, and write a paragraph analyzing the results."]},{"metadata":{"id":"k-Smmf4Axb7g","colab_type":"code","colab":{}},"cell_type":"code","source":["# put your code here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0wL30SkbxuJW","colab_type":"text"},"cell_type":"markdown","source":["# 8.0 Storing Aggregate Data in a DataFrame"]},{"metadata":{"id":"z-m3FNApxwpJ","colab_type":"text"},"cell_type":"markdown","source":["In the last section, we aggregated across brands to understand mean price. We observed that in the top 5 brands, there's a distinct price gap.\n","\n","- Audi, BMW and Mercedes Benz are more expensive\n","- Ford and Opel are less expensive\n","- Volkswagen is in between\n","\n","For the top 5 brands, let's use aggregation to understand the average mileage for those cars and if there's any visible link with mean price. While our natural instinct may be to display both aggregated series objects and visually compare them, this has a few limitations:\n","\n","- it's difficult to compare more than two aggregate series objects if we want to extend to more columns\n","- we can't compare more than a few rows from each series object\n","- we can only sort by the index (brand name) of both series objects so we can easily make visual comparisons\n","\n","\n","Instead, we can combine the data from both series objects into a single dataframe (with a shared index) and display the dataframe directly. To do this, we'll need to learn two pandas methods:\n","\n","- [pandas series constructor](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html)\n","- [pandas dataframe constructor](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n","\n","Here's an example of the series constructor that uses the **brand_mean_prices** dictionary:\n","\n","\n","```python\n","bmp_series = pd.Series(brand_mean_prices)\n","bmp_series\n","\n",">>>\n","audi             9336\n","bmw              8332\n","ford             3749\n","mercedes_benz    8628\n","opel             2975\n","volkswagen       5402\n","dtype: int64\n","```\n","\n","\n","The keys in the dictionary bceame the index in the series object. We can then create a single-column dataframe from this series object. We need to use the **columns** parameter when calling the dataframe constructor (which accepts a array-like object) to specify the column name (or the column name will be set to 0 by default):\n","\n","```python\n","df = pd.DataFrame(bmp_series, columns=['mean_mileage'])\n","df\n","```\n","\n","\n","| | mean_mileage  |      \n","|---------------|------|\n","| bmw           | 8332 |\n","| mercedes_benz | 8628 |\n","| opel          | 2975 |\n","| audi          | 9336 |\n","| volkswagen    | 5402 |\n","| ford          | 3749 |\n","\n","\n","**Exercise**\n","\n","<img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\">\n","\n","\n","- Use the loop method from the last screen to calculate the mean mileage and mean price for each of the top brands, storing the results in a dictionary.\n","- Convert both dictionaries to series objects, using the series constructor.\n","- Create a dataframe from the first series object using the dataframe constructor.\n","- Assign the other series as a new column in this dataframe.\n","Pretty print the dataframe, and write a paragraph analyzing the aggregate data.\n","\n","\n"]},{"metadata":{"id":"5s_nLWR_yQ0W","colab_type":"code","colab":{}},"cell_type":"code","source":["# put your code here"],"execution_count":0,"outputs":[]}]}